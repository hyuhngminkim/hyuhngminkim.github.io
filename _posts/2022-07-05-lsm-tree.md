---
title: 'LSM Tree'
date: 2022-07-05
permalink: /posts/2022/07/lsm-tree/
tags:
  - database
  - in-memory
  - KV store
---

작년에 ICDE에서 발표된 [WipDB](https://ieeexplore.ieee.org/abstract/document/9458602)라는 논문을 보면서 LSM 트리라는 자료구조를 접했습니다. 
LSM 트리를 처음 접하는 것은 아니지만, LSM 트리라는 것이 워낙 많이 쓰이기도 하고, 이 논문과 다른 여러 논문을 읽을 때 도움이 될 것 같아 이 기회에 정리를 해보려고 합니다. 
이 글에서는 LSM 트리가 무엇인지, 어디에 쓰이는지, 어떤 변형들이 있는지 간단하게 정리할 것입니다. 

# Index

## 학부에서 인덱스에 대해 배우셨나요?

우리가 학부에서 배우는 데이터베이스 수업에서는 **인덱스**(index)에 대해서 배웁니다. 
먼저 인덱스에 대해서 가볍게 짚고 넘어가고자 합니다. 

### 데이터의 탐색

꼭 데이터베이스가 아니더라도, 어딘가에 데이터가 저장되어 있다면 우리는 그것을 효율적으로 탐색할 수 있어야 합니다. 
우리가 데이터를 탐색하는 가장 쉽고 직관적인 방식은 처음부터 끝까지 전체 내용을 훑어보는 것이겠죠. 
이것을 우리는 선형 탐색(linear search)이라고 부르며, O(n)의 실행 시간을 가집니다. 
만약 데이터가 정렬되어 있다면, 그 값들을 절반씩 건너뛰며 탐색을 할 수 있습니다. 
이 방법은 이진 탐색(binary search)이라고 부르고, O(log n)의 탐색 시간을 가지죠. 

하지만 어느 쪽이든 장단점이 있습니다. 
선형 탐색은 직관적이고 구현이 쉽지만, 데이터의 양이 많아질수록 비효율적이라는 단점이 있습니다. 
이진 탐색은 선형 탐색에 비해 데이터의 양에 실행 시간이 영향을 덜 받지만, 전체 데이터가 정렬되어 있어야 한다는 전제조건이 붙습니다. 
즉 이진 탐색 자체는 효율적일 수 있지만, 데이터의 순서를 정렬하고 유지하는 데에 추가적인 비용이 듭니다. 

### 인덱스

데이터베이스와 같이 많은 양의 데이터를 다룰 때에는 탐색 알고리즘만으로는 부족할 때가 많습니다. 
그래서 보통 색인, 즉 인덱스를 두죠. 
인덱스를 저장하는 데에 소모되는 추가적인 메모리를 희생해 보다 빠른 탐색 시간을 목표로 하는 것입니다. 

인덱스는 일반적으로 전체 데이터베이스의 크기보다 훨씬 작고, Key-Value의 형태로 데이터를 저장합니다. 
여기서 Key는 우리가 인덱싱하고자 하는 attribute를 저장하고, Value는 해당 Key를 가지는 tuple이 메모리 상에 위치하는 포인터를 저장합니다. 

인덱스를 사용할 때 성능 평가의 기준이 되는 요소는 다음의 다섯 가지가 있습니다. 

- **Access types**: 어떤 종류의 access를 가장 효율적으로 처리하는지를 말합니다. 
특정 값을 찾거나(point query) 특정 범위에 해당하는 값을 찾는(range query) 등의 종류가 이에 해당합니다. 
- **Access time**: 특정 값 혹은 범위의 값을 탐색할 때 걸리는 시간을 말합니다. 
- **Insertion time**: 새로운 값을 추가할 때 소모되는 시간을 말합니다. 
값이 추가될 정확한 위치를 찾을 때 소모되는 시간과 값이 추가될 때 인덱스 구조가 변경되는 데에 소모되는 시간을 모두 포함합니다. 
- **Deletion time**: 기존의 값을 삭제할 때 소모되는 시간을 말합니다. 
삭제될 값의 위치를 찾을 때 소모되는 시간과 값이 삭제될 때 인덱스 구조가 변경되는 데에 소모되는 시간을 모두 포함합니다. 
- **Space overhead**: 인덱스 구조를 유지함에 추가적으로 소모되는 메모리를 말합니다. 

출처: *A. Silberschatz, “Indexing,” in Database system concepts, 7th ed., Ney York: MCGRAW-HILL EDUCATION, 2019, pp. 623–624.*

당연한 말이지만, 이 모든 조건을 동시에 최대로 만족하는 인덱스는 존재하지 않습니다. 
Point query를 빠르게 처리할 수 있으면 range query를 효과적으로 처리하지 못하거나, insertion time이 적게 소모된다면 access time이나 deletion time이 많이 소모되거나 하죠. 
아마 학부때 배우셨을 해시 인덱스(hash index)를 예로 들어보자면, 해시 함수 특성상 특정 값을 매우 빠르게 탐색할 수 있다는 장점이 있습니다. 
우리가 찾는 키를 해시 함수에 통과시킨 후 출력되는 값에 해당하는 버킷(bucket)을 살펴보면 되기 때문입니다. 
하지만 해시 인덱스는 범위 탐색에 매우 취약하다는 단점이 있습니다. 
키 값이 이산적이고 범위가 작다면 그 키들을 해시 함수에 넣어 그 값들에 해당하는 버킷만 살펴보면 되기 때문에 그나마 시간이 덜 소모될 수 있지만, 대부분의 경우 그냥 선형 탐색을 하는 것이 보다 효과적입니다. 
이는 비록 키 값이 연속적이더라도 해시 함수에 따라 전혀 다른 버킷에 배정될 수 있기 때문입니다. 

## B+ Tree

학부에서는 여러 가지 종류의 인덱스에 대해 배웁니다. 
자료구조에서 배우는 기본적인 이진 탐색 트리(binary search tree)에서부터 시작해 데이터베이스에서 다루는 해시 인덱스 또는 비트맵 인덱스(bitmap index) 등을 기억하실 겁니다. 
하지만 그 중에서 가장 대표적인 것은 누가 뭐라 해도 B+ 트리일 것입니다. 
모두들 대충 뭔지는 알지만 어떻게 작동하는지 자세히는 모르는 B+ 트리에 대해서 잠깐 짚고 넘어가고자 합니다. 
이 포스팅에서 다루는 LSM 트리를 이해하는 데에 도움이 되기 때문입니다. 