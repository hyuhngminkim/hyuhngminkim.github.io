---
title: 'LSM Tree'
date: 2022-07-05
permalink: /posts/2022/07/lsm-tree/
tags:
  - database
  - index
  - KV store
---

작년에 ICDE에서 발표된 [WipDB](https://ieeexplore.ieee.org/abstract/document/9458602)라는 논문을 보면서 LSM 트리(log-structured merge tree, LSM Tree)라는 자료구조를 접했습니다. 
LSM 트리를 처음 접하는 것은 아니지만, LSM 트리라는 것이 워낙 많이 쓰이기도 하고, 이 논문과 다른 여러 논문을 읽을 때 도움이 될 것 같아 이 기회에 정리를 해보려고 합니다. 
이 글에서는 LSM 트리가 무엇인지, 어디에 쓰이는지, 어떤 변형들이 있는지 간단하게 정리할 것입니다. 

# Index

## 학부에서 인덱스에 대해 배우셨나요?

우리가 학부에서 배우는 데이터베이스 수업에서는 **인덱스**(index)에 대해서 배웁니다. 
먼저 인덱스에 대해서 가볍게 짚고 넘어가고자 합니다. 

### 데이터의 탐색

꼭 데이터베이스가 아니더라도, 어딘가에 데이터가 저장되어 있다면 우리는 그것을 효율적으로 탐색할 수 있어야 합니다. 
우리가 데이터를 탐색하는 가장 쉽고 직관적인 방식은 처음부터 끝까지 전체 내용을 훑어보는 것이겠죠. 
이것을 우리는 선형 탐색(linear search)이라고 부르며, O(n)의 실행 시간을 가집니다. 
만약 데이터가 정렬되어 있다면, 그 값들을 절반씩 건너뛰며 탐색을 할 수 있습니다. 
이 방법은 이진 탐색(binary search)이라고 부르고, O(log n)의 탐색 시간을 가지죠. 

하지만 어느 쪽이든 장단점이 있습니다. 
선형 탐색은 직관적이고 구현이 쉽지만, 데이터의 양이 많아질수록 비효율적이라는 단점이 있습니다. 
이진 탐색은 선형 탐색에 비해 데이터의 양에 실행 시간이 영향을 덜 받지만, 전체 데이터가 정렬되어 있어야 한다는 전제조건이 붙습니다. 
즉 이진 탐색 자체는 효율적일 수 있지만, 데이터의 순서를 정렬하고 유지하는 데에 추가적인 비용이 듭니다. 

### 인덱스

데이터베이스와 같이 많은 양의 데이터를 다룰 때에는 탐색 알고리즘만으로는 부족할 때가 많습니다. 
그래서 보통 색인, 즉 인덱스를 두죠. 
인덱스를 저장하는 데에 소모되는 추가적인 메모리를 희생해 보다 빠른 탐색 시간을 목표로 하는 것입니다. 

인덱스는 일반적으로 전체 데이터베이스의 크기보다 훨씬 작고, Key-Value의 형태로 데이터를 저장합니다. 
여기서 Key는 우리가 인덱싱하고자 하는 attribute를 저장하고, Value는 해당 Key를 가지는 tuple이 메모리 상에 위치하는 포인터를 저장합니다. 

인덱스를 사용할 때 성능 평가의 기준이 되는 요소는 다음의 다섯 가지가 있습니다. 

- **Access types**: 어떤 종류의 access를 가장 효율적으로 처리하는지를 말합니다. 
특정 값을 찾거나(point query) 특정 범위에 해당하는 값을 찾는(range query) 등의 종류가 이에 해당합니다. 
- **Access time**: 특정 값 혹은 범위의 값을 탐색할 때 걸리는 시간을 말합니다. 
- **Insertion time**: 새로운 값을 추가할 때 소모되는 시간을 말합니다. 
값이 추가될 정확한 위치를 찾을 때 소모되는 시간과 값이 추가될 때 인덱스 구조가 변경되는 데에 소모되는 시간을 모두 포함합니다. 
- **Deletion time**: 기존의 값을 삭제할 때 소모되는 시간을 말합니다. 
삭제될 값의 위치를 찾을 때 소모되는 시간과 값이 삭제될 때 인덱스 구조가 변경되는 데에 소모되는 시간을 모두 포함합니다. 
- **Space overhead**: 인덱스 구조를 유지함에 추가적으로 소모되는 메모리를 말합니다. 

출처: *Silberschatz, Abraham. “Indexing.” Database System Concepts, 7th ed., MCGRAW-HILL EDUCATION, Ney York, 2019, pp. 623–624.*

당연한 말이지만, 이 모든 조건을 동시에 최대로 만족하는 인덱스는 존재하지 않습니다. 
Point query를 빠르게 처리할 수 있으면 range query를 효과적으로 처리하지 못하거나, insertion time이 적게 소모된다면 access time이나 deletion time이 많이 소모되거나 하죠. 
아마 학부때 배우셨을 해시 인덱스(hash index)를 예로 들어보자면, 해시 함수 특성상 특정 값을 매우 빠르게 탐색할 수 있다는 장점이 있습니다. 
우리가 찾는 키를 해시 함수에 통과시킨 후 출력되는 값에 해당하는 버킷(bucket)을 살펴보면 되기 때문입니다. 
하지만 해시 인덱스는 범위 탐색에 매우 취약하다는 단점이 있습니다. 
키 값이 이산적이고 범위가 작다면 그 키들을 해시 함수에 넣어 그 값들에 해당하는 버킷만 살펴보면 되기 때문에 그나마 시간이 덜 소모될 수 있지만, 대부분의 경우 그냥 선형 탐색을 하는 것이 보다 효과적입니다. 
이는 비록 키 값이 연속적이더라도 해시 함수에 따라 전혀 다른 버킷에 배정될 수 있기 때문입니다. 

이런 기본적인 이야기를 하는 이유는 이번 포스팅에서 다루는 LSM 트리를 사용하는 동기를 이해하기 위해서 필요하기 때문입니다. 
LSM 트리를 조금 다룬 뒤, 인덱스의 성능 평가의 기준이 되는 위 다섯 가지 지표로 다시 돌아와 왜 LSM 트리가 고안되었고, 어떤 분야에서 사용되는지를 설명하도록 하겠습니다. 

### B+ Tree

B+ 트리는 LSM 트리를 이해하는 데 있어 상당히 중요합니다. 
원래는 이번 포스팅에 B+ 트리까지 한꺼번에 다룰 생각이었는데, B+ 트리를 얕게 다루자니 너무 내용이 빈약해질 것 같고 깊게 다루자니 너무 내용이 방대해질 것 같아 별도의 포스팅으로 내용을 분리하기로 했습니다. 
([링크](https://hyuhngminkim.github.io/posts/2022/07/bplus-tree/))
B+ 트리에 대해 잘 모르시거나 기억이 나지 않으시면 해당 포스팅을 참고하시는 것도 도움이 될 것입니다. 


# LSM Tree

B+ 트리의 큰 단점 중 하나는 write, delete 등의 업데이트 쿼리가 많을 때 그 성능이 크게 감소한다는 것입니다. 
컴퓨터 구조 혹은 그와 비슷한 과목에서 메모리 계층 구조를 배우셨다면 아시겠지만, 컴퓨터가 메모리를 접근하는 시간과 디스크를 접근하는 시간에는 엄청난 차이가 존재합니다. 
따라서 인덱스의 성능 향상을 위해서는 디스크 접근을 줄이고 메모리 내부에서 최대한 많은 일을 처리할 수 있도록 해야 하는데, B+ 트리는 많은 디스크 접근을 필요로 하기 때문에 이 부분에서 성능 저하가 발생하는 것입니다. 

## The log-structured merge-tree (LSM-tree)

출처: *O’Neil, Patrick, et al. "The log-structured merge-tree (LSM-tree)." Acta Informatica 33.4 (1996): 351-385.*

LSM 트리에 관해 가장 먼저 살펴볼 것은 이것을 처음 제시한 논문입니다. 
1996년에 나온 논문으로, 벌써 30년 가까이 된 논문입니다. 
LSM 트리가 소개된 당시는 지금보다 메모리의 속도도 물론 느렸지만, 메모리의 가격이 훨씬 비쌌고 용량도 적었기 때문에 당시의 메모리는 지금 우리가 사용하는 메모리보다 훨씬 비싼 자원이었습니다. 
[이 표](https://jcmit.net/memoryprice.htm)를 보면, 논문이 발표된 1996년의 메가바이트당 가격(\$/Mbyte)이 5\$에서 30\$ 사이에 형성된 반면, 최근에는 그 가격이 0.0027\$ 언저리에 형성되어 있습니다. 
같은 크기의 메모리를 